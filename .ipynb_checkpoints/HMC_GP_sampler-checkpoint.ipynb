{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import norm\n",
    "import emcee\n",
    "import pandas as pd\n",
    "from tqdm import trange\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline\n",
    "from scipy.special import logsumexp, erf\n",
    "from scipy.optimize import minimize\n",
    "from scipy import stats\n",
    "from scipy.integrate import cumtrapz, quad\n",
    "import pystan\n",
    "\n",
    "# matplotlib set-up\n",
    "columnwidth = 20 # cm\n",
    "aspect = 1.67\n",
    "pts_per_inch = 72.27\n",
    "inch_per_cm = 2.54\n",
    "width = columnwidth/inch_per_cm\n",
    "plt.rcParams.update({'figure.figsize': [width, width / aspect],\n",
    "                                'backend': 'pdf',\n",
    "                                'font.size': 14,\n",
    "                                'legend.fontsize': 14,\n",
    "                                'legend.frameon': False,\n",
    "                                'legend.loc': 'best',\n",
    "                                'lines.markersize': 3,\n",
    "                                'lines.linewidth': 2,\n",
    "                                'axes.linewidth': .5,\n",
    "                                'axes.edgecolor': 'black'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stan model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_code = \"\"\"\n",
    "data {\n",
    "    int num_CC_obs;  // Number of direct observations of the inverse.\n",
    "    vector[num_CC_obs] hz_CC_obs;  // CC H(z)\n",
    "    vector[num_CC_obs] hz_CC_sigma;  // CC noise\n",
    "    int z_CC_ind[num_CC_obs]; // GP node indices of CC redshifts \n",
    "    \n",
    "    int num_SN_obs;  // Number of SN observations.\n",
    "    vector[num_SN_obs] z_SN;  // SN redshifts\n",
    "    vector[num_SN_obs] mu_SN_obs;  // SN obs\n",
    "    matrix[num_SN_obs, num_SN_obs] L_SN;  // Supernovae covariance (Cholesky)\n",
    "    int z_SN_ind[num_SN_obs]; // GP node indices of SN redshifts\n",
    "    \n",
    "    int num_z;  // Number of redshfit nodes for GP\n",
    "    vector[num_z] z; // Redshift nodes for GP\n",
    "    matrix[num_z, num_z] d2; // Square distances for the GP nodes\n",
    "    vector[num_z] mu; // GP mean\n",
    "    matrix[num_z, num_z] epsilon;  // Small value to add to the diagonal of the covariance matrix.\n",
    "    \n",
    "    real<lower=0> A_upper_limit; // Upper limit on kernel amplitude\n",
    "    real<lower=0> l_upper_limit; // Upper limit on kernel length-scale\n",
    "}\n",
    "\n",
    "\n",
    "parameters {\n",
    "    real omegaK; // OmegaK\n",
    "    real M; // SN calibration \n",
    "    real<lower=0> A;  // Scale of the Gaussian process.\n",
    "    real<lower=0> l;  // Correlation length of the Gaussian process.\n",
    "    vector[num_z] n;  // Whitened variables for the Gaussian process.\n",
    "}\n",
    "\n",
    "transformed parameters {\n",
    "    matrix[num_z, num_z] K;  // Covariance for the Gaussian process.\n",
    "    matrix[num_z, num_z] L;  // Cholesky decomposition\n",
    "    vector[num_z] hz;  // Gaussian process\n",
    "    vector[num_z] dc;  // Intgrated values of the Gaussian process.\n",
    "    vector[num_CC_obs] hz_CC;  // Inverse values of the Gaussian process.\n",
    "    vector[num_SN_obs] dc_SN;  // Intgrated values of the Gaussian process at SN redshifts.\n",
    "    vector[num_SN_obs] mu_SN;  // Intgrated values of the Gaussian process.\n",
    "    \n",
    "    // Kernel\n",
    "    K = A ^ 2 * exp(- d2 / (2 * l ^ 2)) + epsilon;\n",
    "    \n",
    "    // Evaluate the observations.\n",
    "    L = cholesky_decompose(K);\n",
    "    hz = L * n + mu;\n",
    "    \n",
    "    // compute the distances at the SN redshifts...\n",
    "    dc[1] = 0; // first distance = 0\n",
    "    for (i in 2:num_z) {\n",
    "        dc[i] = dc[i-1] + hz[1] * (1./hz[i] + 1./hz[i-1])*(z[i] - z[i-1])/2.;  // trapezium rule      \n",
    "    }\n",
    "    \n",
    "    // pull out the distances at the SN redshifts\n",
    "    for (i in 1:num_SN_obs){\n",
    "        dc_SN[i] = dc[z_SN_ind[i]];\n",
    "    }\n",
    "    \n",
    "    // pull out the H(z)s for the CC data\n",
    "    for (i in 1:num_CC_obs) {\n",
    "        hz_CC[i] = hz[z_CC_ind[i]];\n",
    "    }\n",
    "    \n",
    "    // distance moduli for the SN\n",
    "    mu_SN = 5*log10((1. + z_SN) .* (sin(sqrt(fabs(omegaK)) * dc_SN) * (omegaK > 0) + sinh(sqrt(fabs(omegaK)) * dc_SN) * (omegaK < 0))/sqrt(fabs(omegaK))) - 5*log10(hz_CC[1]) + M;\n",
    "}\n",
    "\n",
    "model {\n",
    "    A ~ uniform(0, A_upper_limit);\n",
    "    l ~ uniform(0, l_upper_limit);\n",
    "    n ~ normal(0, 1);\n",
    "    hz_CC_obs ~ normal(hz_CC, hz_CC_sigma);\n",
    "    mu_SN_obs ~ multi_normal_cholesky(mu_SN, L_SN);\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pystan.StanModel(model_code=model_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SN data (Pantheon)\n",
    "mu_SN = pd.read_csv('lcparam_DS17f.txt', delim_whitespace=True, header=None, names=['mb'], usecols=(4,), skiprows=1).mb.values\n",
    "mu_SN_sigma = pd.read_csv('lcparam_DS17f.txt', delim_whitespace=True, header=None, names=['dmb'], usecols=(5,), skiprows=1).dmb.values\n",
    "z_SN = pd.read_csv('lcparam_DS17f.txt', delim_whitespace=True, header=None, names=['zcmb'], usecols=(1,), skiprows=1).zcmb.values\n",
    "C_SN = np.genfromtxt('syscov_panth.txt') + np.diag(mu_SN_sigma**2)\n",
    "\n",
    "# CC data (31 points compiled)\n",
    "z_CC, hz_CC, hz_CC_sigma = np.loadtxt('cc_HZ_data_comp.txt', unpack = True, usecols=(0,1,2))\n",
    "N_CC = np.diag(hz_CC_sigma**2)\n",
    "\n",
    "# augment the CC data with a value for H0\n",
    "z_CC = np.concatenate([np.array([0.]), z_CC])\n",
    "hz_CC = np.concatenate([np.array([70.]), hz_CC])\n",
    "hz_CC_sigma = np.concatenate([np.array([100.]), hz_CC_sigma])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a GP to the LCDM solution, just for initializing the hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute fiducial LCDM H(z) on a redshift grid\n",
    "z = np.linspace(0, 2, 40)\n",
    "d2 = cdist(np.atleast_2d(z).T, np.atleast_2d(z).T)**2\n",
    "omegaM = 0.3\n",
    "H0 = 68\n",
    "gp_mean_ = 100.\n",
    "gp_mean = lambda x: gp_mean_ + x*0.\n",
    "hz = H0*np.sqrt((1.-omegaM) + omegaM*(1+z)**3)\n",
    "\n",
    "# marginal posterior for the hyper-parameters\n",
    "def log_posterior_hyperparameters(theta, upper):\n",
    "    \n",
    "    A = theta[0]\n",
    "    l = theta[1]\n",
    "    l2 = theta[1]**2\n",
    "    \n",
    "    if A > upper[0] or np.sqrt(l2) > upper[1] or A <= 0 or l <= 0:\n",
    "        return -np.inf\n",
    "    else:\n",
    "        K = (A**2)*np.exp(-0.5*d2/l2) + 1e-8*np.eye(len(d2))\n",
    "        K_inv = np.linalg.inv(K)\n",
    "        _, logdetK = np.linalg.slogdet(K)\n",
    "\n",
    "        log_target = -0.5*np.dot(hz - gp_mean(z), np.dot(K_inv, hz - gp_mean(z))) - 0.5*logdetK\n",
    "\n",
    "        if np.isnan(log_target):\n",
    "            return -np.inf\n",
    "        else:\n",
    "            return log_target\n",
    "        \n",
    "# run the sampling\n",
    "nparameters = 2\n",
    "nwalkers = 200\n",
    "nsteps = 200\n",
    "walkers = np.array([40, 3]) + np.random.uniform(-0.05, 0.05, (nwalkers, 2))\n",
    "upper = np.array([1000, 20.])\n",
    "sampler = emcee.EnsembleSampler(nwalkers, nparameters, log_posterior_hyperparameters, args=[upper])\n",
    "result = sampler.run_mcmc(walkers, nsteps, progress=True)\n",
    "samples = sampler.chain[:,100:,:].reshape(-1, nparameters)\n",
    "\n",
    "# plot the samples (check nothing crazy happened)\n",
    "plt.scatter(samples[:,0], samples[:,1], s = 0.01)\n",
    "plt.xlabel('amplitude, $A$')\n",
    "plt.ylabel('length scale, $l$')\n",
    "plt.show()\n",
    "\n",
    "# set initial kernel hyper-parameters to the medians found here\n",
    "A = np.median(samples[:,0])\n",
    "ell = np.median(samples[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization for the HMC sampler (NB: initialize at rough kLCDM best fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redshift grid for the (latent) Gaussian process\n",
    "n_between = 3 # how many redshift grid points to have in between each SN redshift (for computing the trapz integrals)?\n",
    "z = np.concatenate([np.concatenate([np.linspace(0, z_SN[0], n_between + 1)] + [np.linspace(z_SN[i], z_SN[i+1], n_between + 1)[1:] for i in range(0, len(z_SN)-1)]), z_CC])\n",
    "z = np.sort(np.unique(z))\n",
    "\n",
    "# which indices of the redshift grid correspond to the SN and CC redshifts respectively (NB: +1 due to stan indices starting at 1)\n",
    "z_SN_ind = [np.where(z == z_SN[i])[0][0] + 1 for i in range(len(z_SN))]\n",
    "z_CC_ind = [np.where(z == z_CC[i])[0][0] + 1 for i in range(len(z_CC))]\n",
    "\n",
    "# square distances for the redshift grid (for the GP kernel)\n",
    "d2 = cdist(np.atleast_2d(z).T, np.atleast_2d(z).T)**2\n",
    "\n",
    "# initialize kernel\n",
    "epsilon = np.eye(len(z)) * 1e-5\n",
    "K = A**2 * np.exp(-0.5 * d2 / ell**2) + epsilon\n",
    "L = np.linalg.cholesky(K)\n",
    "Linv = np.linalg.inv(L)\n",
    "\n",
    "# fiducial parameters\n",
    "omegaK = 1e-2\n",
    "omegaM = 0.28\n",
    "H0 = 68.\n",
    "M = 32.975\n",
    "H = lambda z: H0*np.sqrt(1. - omegaM + omegaM*(1+z)**3)\n",
    "hz = H(z)\n",
    "\n",
    "# initial innovation vector\n",
    "n = np.dot(Linv, hz - gp_mean(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs for the HMC sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "data = { # CC data\n",
    "       \"num_CC_obs\":len(hz_CC),\n",
    "       \"hz_CC_obs\":hz_CC,\n",
    "       \"z_CC_ind\":z_CC_ind,\n",
    "       \"hz_CC_sigma\":hz_CC_sigma,\n",
    "\n",
    "       # SN data\n",
    "       \"num_SN_obs\":40,\n",
    "       \"z_SN_ind\":z_SN_ind,\n",
    "       \"z_SN\":z_SN,\n",
    "       \"mu_SN_obs\":mu_SN,\n",
    "       \"L_SN\":np.linalg.cholesky(C_SN),\n",
    "       \n",
    "       # Redshift grid and GP set-up\n",
    "       \"z\":z,\n",
    "       \"num_z\":len(z),\n",
    "       \"epsilon\":1e-5*np.eye(len(z)),\n",
    "       \"mu\":gp_mean(z),\n",
    "       \"d2\":d2,\n",
    "    \n",
    "       # prior limits on kernel parameters\n",
    "       \"A_upper_limit\":700,\n",
    "       \"l_upper_limit\":20\n",
    "}\n",
    "\n",
    "# initial parameter values\n",
    "init = {\"n\":n,\n",
    "       \"omegaK\":omegaK,\n",
    "       \"M\":M,\n",
    "       \"A\":A,\n",
    "       \"l\":ell}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a time consuming step, takes ~ 10 hours\n",
    "fit = model.sampling(data=data, init=[init], warmup=3500, iter=15000, chains=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the resulting constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omegaK = fit['omegaK']\n",
    "x = np.linspace(min(omegaK), max(omegaK), 500)\n",
    "y = stats.gaussian_kde(omegaK)(x)\n",
    "plt.plot(x, y)\n",
    "plt.hist(omegaK, bins=50, alpha=0.2, density=True)\n",
    "plt.xlabel(r'curvature, $\\Omega_\\mathrm{K}$')\n",
    "ax = plt.gca()\n",
    "ax.yaxis.set_ticklabels([])\n",
    "print(np.median(omegaK), np.std(omegaK))\n",
    "plt.ylabel('posterior density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MultipleLocator\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "minorLocator   = MultipleLocator(0.1)\n",
    "minorLocator2   = MultipleLocator(10)\n",
    "\n",
    "ax.xaxis.set_minor_locator(minorLocator)\n",
    "ax.yaxis.set_minor_locator(minorLocator2)\n",
    "\n",
    "line, = plt.plot(z, np.mean(fit[\"hz\"], axis=0), color='k')\n",
    "plt.fill_between(z, np.mean(fit[\"hz\"], axis=0) - 2*np.std(fit[\"hz\"], axis=0), np.mean(fit[\"hz\"], axis=0) + 2*np.std(fit[\"hz\"], axis=0), alpha = 0.2, color = 'b', label='95%')\n",
    "plt.fill_between(z, np.mean(fit[\"hz\"], axis=0) - np.std(fit[\"hz\"], axis=0), np.mean(fit[\"hz\"], axis=0) + np.std(fit[\"hz\"], axis=0), alpha = 0.5, color='r', label='68%')\n",
    "plt.errorbar(z_CC[1:], hz_CC[1:], yerr=hz_CC_sigma[1:], fmt='.k')\n",
    "plt.xlabel('redshift, $z$', fontsize=25)\n",
    "plt.ylabel(r'$H(z)\\, km\\,s^{-1}Mpc^{-1}$', fontsize=25)\n",
    "plt.legend(frameon=False, prop={'size':15})\n",
    "plt.title('Squared Exponential kernel', fontsize=25, pad=3)\n",
    "plt.tick_params(width=3, length=7, direction=\"in\", labelsize=15)\n",
    "plt.tick_params(width=2, length=4, direction=\"in\", which=\"minor\", labelsize=10)\n",
    "plt.xlim(0., 2.6)\n",
    "plt.savefig('plots/ExpansionHistory_Current.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
